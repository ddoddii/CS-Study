### Operating System

<details>
<summary>📚 공부한 자료</summary>

- 혼자 공부하는 컴퓨터구조 / 운영체제
- 실습과 그림으로 배우는 리눅스 구조
- Operating System Concepts

</details>

### **1. 시스템 콜이 무엇인지 설명해 주세요.**

시스템 콜이란 사용자 모드로 실행되는 프로그램이 자원에 접근하는 운영체제 서비스를 제공받기 위해 **운영체제의 커널 기능을 사용하도록 요청** 하는 것입니다. 시스템콜은 일종의 소프트웨어적 인터럽트이다.

- **우리가 사용하는 시스템 콜의 예시를 들어주세요.**
  - 파일 관련: `open()`, `read()`, `write()`, `close()`
  - 프로세스 관련: `fork()`, `exec()`, `wait()`, `exit()`
  - 통신 관련: `socket()`, `bind()`, `listen()`, `accept()`
- **시스템 콜이, 운영체제에서 어떤 과정으로 실행되는지 설명해 주세요.**
  - 유저 어플리케이션에서 라이브러리에 구현된 시스템 콜을 호출합니다. 그 후 소프트웨어 인터럽트를 통해 커널 모드로 모드 스위칭이 일어납니다. 커널 모드로 전환 후 커널은 시스템 콜 번호를 확인하고, 시스템 콜 테이블에서 해당하는 함수 포인터를 실행합니다. 작업이 완료되면 다시 유저 모드로 전환 후 유저 어플리케이션에서 결과를 반환합니다. 

  <details>
  <summary>xv6 에서 시스템 콜 테이블 예시</summary>


  <img width="226" alt="image" src="https://github.com/ddoddii/ddoddii.github.io/assets/95014836/d2841343-9da5-4649-b7bf-7d7180213cf6">

  </details>


- **시스템 콜의 유형에 대해 설명해 주세요.**
  - 프로세스 생성 및 종료, 중지 등 프로세스와 관련된 시스템 콜, 
  파일 시스템에 접근하여 파일을 생성, 삭제, 수정 등 파일과 관련된 시스템 콜, 디바이스와 관려된 시스템 콜, 시스템 시간, 프로세스, 파일 속성 등 시스템과 관련된 정보를 관리하는 시스템콜, IPC 또는 네트워크 통신을 위한 시스템 콜, 파일 접근 권한을 설정하는 등 보안과 관련된 시스템 콜이 있습니다.


- **운영체제의 Dual Mode 에 대해 설명해 주세요.**
  - **유저 모드(User Mode):** 유저 모드에서 실행되는 유저 프로세스는 제한된 CPU명령어 집합만 사용 가능하며, 시스템 하드웨어에 직접적으로 접근할 수 없습니다.
  - **커널 모드(Kernel Mode):** 커널 모드에서 실행되는 커널은 모든 CPU 명령어 사용이 가능하고, 모든 리소스에 접근이 가능합니다.
- **왜 유저모드와 커널모드를 구분해야 하나요?**
  - 유저 모드와 커널 모드를 분리하여, 신뢰할 수 있는 커널만이 시스템과 관련된 리소스에 접근을 허용하고, 유저 프로세스의 권한을 최소화하여 시스템 오류를 일으킬 수 있는 가능성을 최소화합니다.
- **서로 다른 시스템 콜을 어떻게 구분할 수 있을까요?**
  - 시스템 콜 호출시 레지스터에 시스템 콜을 식별할 수 있는 시스템 콜 번호를 저장해놓고,
커널이 시스템 콜 테이블을 통해 해당 시스템 콜 번호에 상응하는 서비스 루틴을 수행합니다.

- **유저모드에서 커널 모드로 바뀌는 상황에는 어떤 것이 있을까요?**
  - 인터럽트, 예외, 시스템 콜이 발생한 상황이 있습니다. 인터럽트는 주로 하드웨어 디바이스가 발생시킵니다. 예외는 프로그램의 예상하지 못한 오류가 발생했을 때 (0으로 나눴을 경우) 발생합니다. 시스템 콜은 예외와 달리 사용자가 의도한 명령으로, 커널에게 대신 어떤 요청하기 위해 발생시킵니다. 

### **2. 인터럽트가 무엇인지 설명해 주세요.**

인터럽트란 CPU가 특정 기능을 수행하는 도중에 급하게 다른 일을 처리하고자 할 때 사용할 수 있는 기능으로, CPU 의 작업을 방해하는 신호이다. 인터럽트의 종류에는 크게 내부/외부 인터럽트가 있다. 

내부 인터럽트에는 CPU 명령에 의해 의도적으로 만들어낸 것으로, 예외와 시스템콜이 있다. 외부 인터럽트에는 타이머 인터럽트, I/O 인터럽트, 전원 이상 인터럽트가 있다.


- **인터럽트는 어떻게 처리하나요?**
  - 하드웨어 인터럽트의 경우 장치 컨트롤러가 CPU의 IRQ 라인에 신호를 보냅니다.
  - CPU는 현재 실행중인 프로세스의 컨텍스트를 저장해놓고 커널 모드로 스위칭합니다.
  - 커널은 인터럽트 벡터 테이블에서 상응하는 인터럽트 핸들러를 찾고 서비스를 수행합니다.
  - 인터럽트 처리가 완료되면 진행중이었던 작업의 컨텍스트를 복원하고 유저 모드로 스위칭하여 프로세스를 재개합니다.
- **Polling 방식에 대해 설명해 주세요.**
  - 폴링은 주기적으로 CPU에 연결된 장치들을 순차적으로 검사하여 서비스를 요청하는지 확인합니다. CPU가 메모리에 매핑된 각 장치의 상태를 확인하면서 서비스를 수행하고 위와 같은 과정을 계속 반복합니다.
  - (CPU 가 주체적으로 디바이스 컨트롤러의 버퍼를 확인)
- **HW / SW 인터럽트에 대해 설명해 주세요.**
  - 하드웨어 인터럽트는 타이머, 디스크, NIC 등 외부 장치의 컨트롤러로부터 프로세서에 발생된 인터럽트입니다.
  - 소프트웨어 인터럽트는 CPU 명령어에 의해 발생된 인터럽트입니다. 
- **동시에 두 개 이상의 인터럽트가 발생하면, 어떻게 처리해야 하나요?**
  - 하나의 CPU에서 여러 IRQ 라인에 신호가 들어와있으면 그 중 우선순위가 높은 인터럽트부터 수행합니다. 혹은 인터럽트 수행 중에 다른 인터럽트가 발생하면 중첩 인터럽트 방식으로 처리할 수 있습니다.


### **3. 프로세스가 무엇인가요?**


```text
프로세스는 CPU 가 자원을 할당해주는 작업의 단위로, 실행 중인 프로그램의 인스턴스이다. CPU 가 할당해주는 자원에는 CPU 시간, 운영에 필요한 주소 공간, (코드, 데이터, 힙, 스택) 구조로 되어있는 독립된 메모리 영역이 있다. 

- 각각 독립된 메모리 영역을 할당받는다. 
- 프로세스 당 최소 1개의 스레드(메인 스레드)를 가지고 있다. 
- 각 프로세스는 별도의 주소 공간에서 실행되며, 한 프로세스는 다른 프로세스의 변수나 자료구조에 접근할 수 없다. 
- 한 프로세스가 다른 프로세스의 자원에 접근하려면 IPC를 사용해야 한다. 
```

- **프로그램과 프로세스, 스레드의 차이에 대해 설명해 주세요.**
  - 프로그램은 코드가 컴파일 된 파일과 같이 정적인 개념이고, 프로세스는 이러한 파일이 메인 메모리에 적재되어 실행되고 있는 하나의 인스턴스를 의미합니다. 
  - 스레드는 프로세스 내에서 실행되는 단위로 볼 수 있습니다. 프로세스가 할당받은 자원을 이용하여 실행되며,  같은 프로세스 내의 스레드들은 프로세스의 heap, data, code 영역을 공유합니다.

- **프로세스 상태는 어떤 것이 있나요?**
  - new : 프로세스가 생성되고 초기화되는 상태
  - running : 명령어들이 실행 중
  - waiting(blocked) : 실행중인 프로세스가 I/O와 같이 요청한 작업이 완료되기를 기다리고 있는 상태
  - ready : 프로세스가 실행 준비가 되어 레디큐에서 기다리고 있는 상태
  - terminated : 실행을 완료하고 시스템에서 제거되는 상태

- **PCB가 무엇인가요?**
  - PCB는 프로세스와 관련된 메타 데이터를 가지고 있는 디스크립터로, 프로세스의 상태, PID, 스케줄링 정보, 메모리 정보, PC 및 레지스터 상태 등 프로세스의 주요 정보를 저장하고 있습니다.
- **그렇다면, 스레드는 PCB를 갖고 있을까요?**
  - 개념적으로는 스레드의 디스크립터를 TCB라는 용어로 구분합니다. TCB는 프로세스의 PCB처럼 스레드의 메타데이터를 저장하는 자료구조입니다.
  - 리눅스를 기준으로 설명을 드리면, 리눅스는 쓰레드를 구현하기 위해 새로운 자료구조를 만들지 않고 스레드를 프로세스의 메모리를 공유할 수 있는 프로세스로 취급하여 구현하였습니다. 따라서 프로세스의 PCB인 task_struct 구조체를 그대로 TCB로 사용하고 있습니다.



- **리눅스에서, 프로세스와 스레드는 각각 어떻게 생성될까요?**
  - 리눅스에서 프로세스는 `fork()` 시스템콜로 생성됩니다.
  - 쓰레드는 `clone()` 시스템 콜에 플래그를 지정하여 생성할 수 있습니다.


- **자식 프로세스가 상태를 알리지 않고 죽거나, 부모 프로세스가 먼저 죽게 되면 어떻게 처리하나요?**
  - 이런 프로세스의 부모는 pid가 1인 'init'가 되며, 'init' 프로세스는 주기적으로  wait 함수를 호출하여 해당 프로세스를 정리합니다.
- **리눅스에서, 데몬프로세스에 대해 설명해 주세요.**
  - 데몬 프로세스는 백그라운드에서 실행되는 특별한 종류의 프로세스로, 유저의 개입 없이 시스템 부팅시  자동으로 시작되며 시스템이 종료될 때까지 계속 실행됩니다.
  - 네트워크, 파일 관리 같은 필수 시스템 서비스를 제공합니다.


- **리눅스는 프로세스가 일종의 트리를 형성하고 있습니다. 이 트리의 루트 노드에 위치하는 프로세스에 대해 설명해 주세요.**
  - 루트 노드에 위치하는 프로세스는 'init' 프로세스로 pid로 1을 갖습니다.
  - 최근에는 'systemd'가 주로 사용되는데, 이 프로세스는 시스템이 부팅될 때 가장 먼저 시작되며, 다른 모든 유저 프로세스의 직간접적 부모가 됩니다. 또한 다양한 시스템에 기본적인 데몬 프로세스를 실행시킵니다.
- **프로세스와 쓰레드가 실제 사용되는 예시에 대해 설명해 주세요.⭐️**
  - 크롬의 탭들은 멀티 프로세스로 설계되었습니다.
  - 웹서버(Nginx) 는 각 요청을 쓰레드로 처리합니다. 웹 서버 프로세스를 시작하면 HTTP요청을 수신하는 스레드를 생성합니다. 해당 스레드가 HTTP 요청을 받으면 웹페이지 반환과 같은 요청 처리를 담당할 스레드를 스레드 풀에서 선택하여 위임합니다.

---✅

### **4. 프로세스 주소공간에 대해 설명해 주세요.**

각 프로세스는 자신만이 접근할 수 있는 메모리 영역을 할당 받습니다. 이러한 메모리를 효율적으로 관리하기 위해 프로세스 관점에서 해당 주소 공간을 코드, 데이터, 힙, 스택 영역으로 나눕니다.

- **프로세스의 4가지 영역은 무엇인가요?**
  - **코드 영역**은 실제 수행되는 코드가 컴파일 되어 CPU명령어가 바이너리로 저장되어 있는 영역이고, **데이터 영역**은 전역 변수나 static 변수 등 프로세스 시작과 함께 생성되는 데이터가 저장되어 있는 영역이고, **힙 영역**은 런타임에 동적으로 할당한 데이터를 저장하는 영역이고, **스택 영역**은 함수 호출과 함께 할당되며 지역 변수, 매개 변수 등 함수 스코프 내의 데이터가 저장되어 있는 영역입니다.
- **초기화 하지 않은 변수들은 어디에 저장될까요?**
  - 운영체제의 프로세스 주소 공간에서 초기화되지 않은 변수들은 주로 "**BSS 세그먼트**" (Block Started by Symbol)에 위치합니다.

- **일반적인 주소공간 그림처럼, Stack과 Heap의 크기는 매우 크다고 할 수 있을까요? 그렇지 않다면, 그 크기는 언제 결정될까요?**
  - 먼저 주소 공간 상에서 스택은 위에서 아래로, 힙은 아래에서 위로 증가합니다. 따라서 무한정 증가할 수 없습니다. 스택의 초기 크기는 컴파일 타임에 결정됩니다. 런타임에서 함수 호출시 마다 스택에 데이터가 할당되며 초기 크기가 넘는 공간이 필요하다면 확장이 가능하나, 최대 확장 크기를 넘어서게 되면 스택 오버플로우가 발생합니다.

  - 힙의 초기 크기도 운영체제나 프로그램에 의해 설정되며 malloc, new 등에 의해 데이터가 할당되면 힙의 크기가 동적으로 증가하며 해제되면 감소합니다. 일반적으로 힙은 스택보다 훨씬 큰 메모리 영역을 사용할 수 있습니다.

- **Stack과 Heap 공간에 대해, 접근 속도가 더 빠른 공간은 어디일까요?**
  - 결론부터 말하면 스택에 접근하는 것이 빠릅니다. 스택에 할당된 데이터에는 레지스터에 저장된 스택 포인터에 더하기 빼기와 같은 단일 CPU 명령어로 접근합니다.
  - 반면 힙에 할당한 변수에 접근하기 위해서는, 동적 할당한 힙 영역에 있는 데이터의 주소를 받아오고 이를 변수에 저장해야 합니다. 스택 내에 저장된 주소에 접근한 뒤에 해당 주소에 대해 load연산을 CPU단에서 한번 더 해야하므로 느립니다.
- **다음과 같이 공간을 분할하는 이유가 있을까요?**
  - 첫번째로, 스택, 힙, 데이터, 코드 각 영역마다 서로 접근 권한을 분리해야 합니다. 예를 들어, 코드 영역에서 읽고 실행하는 것은 가능하지만 쓰기는 제한하여 악의적인 코드 실행을 막아야 합니다. 따라서 이러한 영역들을 분리하고 접근 권한을 따로 관리할 수 있습니다.

  - 두번째로, 스택과 힙에 동적으로 메모리를 할당하고 요구에 따라 크기를 조정할 수 있습니다. 또한 스택과 힙이
반대로 증가하게 하여 크기에 제한을 둘 수 있습니다.
- **스레드의 주소공간은 어떻게 구성되어 있을까요?**
  - 스레드는 프로세스 내의 주소공간을 공유하므로, 기본적으로 스레드를 생성한 프로세스의 주소공간과 같습니다. 그러나 각자 서로 다른 실행의 흐름을 가지므로 스레드마다 개별 스택을 가지고 있습니다.


- **"스택"영역과 "힙"영역은 정말 자료구조의 스택/힙과 연관이 있는 걸까요? 만약 그렇다면, 각 주소공간의 동작과정과 연계해서 설명해 주세요.**
  - 스택 자료구조는 LIFO구조를 갖습니다. 메모리의 스택 영역도 가상 메모리상에서 위에서 아래로 순서대로
데이터가 할당되며 해제도 아래에서 위로 이뤄집니다.
  - 힙 영역은 자료구조 힙의 동작과정과 크게 상관없는 것으로 알고 있습니다.
- **그렇다면 동적 메모리 할당이란 무엇인가요? 여기서 메모리 누수는 어떤 상황일 때 발생할까요?**
  - 컴파일 타임에 메모리를 할당하는 것이 아니라 런타임에, 즉 프로그램 실행 중에 메모리를 할당하는 것을 의미합니다.
이러한 메모리는 힙 영역에 할당됩니다.

  - 메모리 누수는 동적으로 할당된 메모리가 더 이상 필요 없음에도 해제되지 않는 상황을 말합니다. 자바에서는 두 객체가 순환 참조하고 있는 경우 가비지 콜렉터가 어느 것도 해제 대상으로 선정하지 못해 발생할 수 있습니다.
- **IPC의 Shared Memory 기법은 프로세스 주소공간의 어디에 들어가나요? 그런 이유가 있을까요?**
  - Shared Memory는 힙 영역에 위치합니다.
  - 프로세스에 따라 필요한 공유 메모리의 크기가 다르므로 컴파일 타임에 이를 결정할 수 없습니다. 따라서 런타임에 해당 메모리를 동적으로 할당해야 합니다.
- **스택과 힙영역의 크기는 언제 결정되나요? 프로그램 개발자가 아닌, 사용자가 이 공간의 크기를 수정할 수 있나요?**
  
- **재귀함수의 작동 원리를 call stack 과 관련해서 설명해주세요.**
  - 함수 내에서 함수가 호출되면 실행하고 있던 콜 스택 아래에 새로운 콜 스택이 만들어집니다. 이러한 과정을 반복하여 최종 재귀함수의 베이스 케이스에서 종료되면 반대 순서로 콜 스택이 하나씩 해제 됩니다.

### **5. 단기, 중기, 장기 스케쥴러에 대해 설명해 주세요.**

- 장기 : 시스템에 제출한 작업을 결정하는 Job Scheduling 에서 사용하며, 시스템 내에 프로세스 수를 조절한다.
- 중기 : 메모리 할당을 결정하는 Memory Allocation 에서 사용한다.
- 단기 : 프로세서를 할당 받을 프로세스를 결정하는 Process Scheduling 에서 사용한다. 


- **현대 OS에는 단기, 중기, 장기 스케쥴러를 모두 사용하고 있나요?**
- **프로세스의 스케쥴링 상태에 대해 설명해 주세요.**
  - 스케쥴링 상태에는 new, running, ready, waiting, terminated 이 있다.
- **preemptive/non-preemptive 에서 존재할 수 없는 상태가 있을까요?**
  - 비선점형 방식에서는 한 프로세스가 CPU를 점유하고 있는 동안 강제로 빼앗을 수 없습니다. 따라서 Running 상태에 있는 프로세스는 스스로 CPU를 양보하기 전까지 중단될 수 없습니다. 따라서 Ready 상태는 존재할 수 없습니다.

- **Memory가 부족할 경우, Process는 어떠한 상태로 변화할까요?**
  - 메모리 부족으로 인해 프로세스가 필요한 메모리를 할당받지 못하면 해당 프로세스는 일시적으로 Waiting 상태로 전환됩니다.
  - 메모리가 부족할 경우 메모리 관리 방법중 하나인 스와핑이 발생할 수 있습니다. 이때 메모리에 있던 프로세스의 일부 또는 전체가 보조 기억 장치(하드디스크 등)로 내려가게 됩니다.
  - 메모리 부족 상황이 지속되고 해결되지 않으면 운영체제는 프로세스를 강제 종료시킬 수 있습니다. 이때 해당 프로세스는 종료 상태가 됩니다. 

### **6. 컨텍스트 스위칭 시에는 어떤 일들이 일어나나요?**

```text
프로세스A -> 프로세스B 컨텍스트 스위칭
1. Interrupt 나 시스템 호출에 의해 컨텍스트 스위칭 요구
2. A의 현재 상태(하드웨어 - CPU 레지스터, 스택 포인터 ..., 메모리 컨텍스트- 프로세스 가 연 파일 목록,.. ) 을 A의 커널 스택에 저장
3. 유저모드에서 커널 모드로 변경
4. 트랩 핸들러로 점프
5. 커널에서 switch() 루틴 호출 (A의 레지스터를 PCB(A) 에 저장, PCB(B)에서 B의 레지스터 복구)
6. 커널 스택 B에서 레지스터 B 복구
7. 커널 모드에서 유저 모드로 변경
8. 프로세스B 실행
```

- **프로세스와 스레드는 컨텍스트 스위칭이 발생했을 때 어떤 차이가 있을까요?**
  - 프로세스 내의 **스레드**는 메모리 영역을 공유하고 있으므로 페이지 테이블, 메모리 관리 정보와 같이 프로세스의 
주소 공간을 나타내는 정보들을 유지한 채로, 프로그램 카운터, 스택, CPU 레지스터 상태 등만 교체하면 됩니다.
  - 그러나 **프로세스** 간 컨텍스트 스위칭이 발생할때는 주소 공간이 교체되어야 하므로 오버헤드가 더 큽니다.

- **컨텍스트 스위칭이 발생할 때, 기존의 프로세스 정보는 커널스택에 어떠한 형식으로 저장되나요?**

  (컨텍스트 스위칭 / 모드 스위칭은 구분해야 함 !!)

  - 컨텍스트 스위칭이 발생할 때 기존 프로세스의 정보는 커널 스택(Kernel Stack)에 PCB(Process Control Block) 데이터 구조 형태로 저장됩니다. 
  - 컨텍스트 스위칭이 발생하면 CPU의 현재 상태인 레지스터 값들과 프로그램 카운터 값 등이 해당 프로세스의 PCB에 저장됩니다. 이렇게 저장된 PCB는 커널 스택에 push 됩니다. 반대로 새로운 프로세스가 실행되려면 커널 스택에서 해당 프로세스의 PCB를 pop하여 그 정보로 CPU의 컨텍스트를 복원합니다.
  - 모드 스위칭 할때 유저 모드 -> 커널 모드로 바꿀 때 커널스택에 저장됨.
  - 리눅스 3(커널), 1(유저) - 모드 스위칭 오버헤드를 줄이기 위해서. 그때 사용되는게 커널 스택. 
- **컨텍스트 스위칭은 언제 일어날까요?**
  - 첫번째로, 현재 실행중이던 프로세스가 타임 슬라이스를 모두 사용했을 때, 타이머 인터럽트가 발생한 후 스케줄러가 해당 프로세를 중지하고 다른 프로세스를 스케줄할때 발생합니다. 
  - 두번째로, 타임 슬라이스를 모두 사용하지 않더라도 특정 I/O 이벤트를 기다리는 등 프로세스가 wait 상태로  전환되면 다른 프로세스를 스케줄할 때 발생합니다.

### **7. 프로세스 스케줄링 알고리즘에는 어떤 것들이 있나요**

- **프로세스 스케줄링 알고리즘**
  - 비선점형에는 FIFO, SJF 가 있습니다. FIFO 의 convoy effect 를 해결한 것이 SJF 이다. 
  - 선점형에는 STCF, RR, Priority Scheduling, MLFQ 가 있다. SJF 에서 작업들이 동시에 오지 않을 경우 여전히 convoy effect 가 발생해서, 이를 해결한 것이 작업이 도착할 때마다 작업의 남은 시간을 계산해서 가장 짧은 남은 시간을 가진 작업을 우선적으로 실행한다. 하지만 남은 시간이 오래 걸리는 작업은 계속해서 실행되지 못하는 기아 현상이 발생할 수 있다.  RR은 타임 슬라이스만큼 주고 작업을 번갈아가며 실행하여, RR에서는 기아 문제가 해결되며 응답시간이 짧아진다. 정적 우선순위 스케쥴링은 작업마다 고정된 우선순위를 할당해주고 우선순위가 높은 것들을 먼저 실행시키는 방식이다. 여기서도 우선순위가 낮은 작업은 CPU 할당을 못받는 기아 문제가 생긴다. 
  - MLFQ 는 각 우선순위 레벨마다 작업 큐를 두는 방식이다. 우선순위가 다르면 우선순위가 높은 작업을 실행하고, 우선순위가 동일할 시 Round Robin 방식으로 진행한다. 작업이 시스템에 처음 도착하면 우선순위가 가장 높다. 만약 실행 중 타임 슬라이스를 모두 쓰면 CPU bound 작업이므로 우선순위가 한단계 낮아진다. 타임 슬라이스가 끝나기 전 CPU 를 양도하면 우선순위를 유지한다. 이때도 기아 현상이 발생할 수 있기 때문에 특정 시간 후에는 가장 높은 우선순위로 올려준다. 하나의 레벨마다 주어진 타임 할당 시간을 다 쓰면, 우선순위가 한단계 낮아진다. 
- **RR을 사용할 때, Time Slice에 따른 trade-off를 설명해 주세요.**
  - **짧은 Time Slice:** 응답 시간은 개선되지만, 컨텍스트 스위칭이 빈번하게 발생하여 오버헤드가 증가합니다.
  - **긴 Time Slice:** 하나의 프로세스가 오래 CPU를 사용하고 있으므로 유저에게 있어 반응 속도가 느릴 수 있습니다. 
- **싱글 스레드 CPU 에서 상시로 돌아가야 하는 프로세스가 있다면, 어떤 스케쥴링 알고리즘을 사용하는 것이 좋을까요? 또 왜 그럴까요?**
  - 정해진 답은 없다. 각 알고리즘마다 장단점이 있다.
  - RR → 모든 프로세스에게 CPU 사용 시간을 동등하게 제공
- **동시성과 병렬성의 차이에 대해 설명해 주세요.**
- **타 스케쥴러와 비교하여, Multi-level Feedback Queue는 어떤 문제점들을 해결한다고 볼 수 있을까요?**
  - **Multi-level Feedback Queue** 에서는 프로세스들이 큐 사이를 이동할 수 있다. 새로 준비 상태가 된 프로세스가 있다면 우선순위가 가장 높은 우선순위 큐에 삽입되고, 일정 시간(타임슬라이스) 만큼 실행된다. 만약 프로세스가 해당 큐에서 실행이 끝나지 않는다면 다음 큐에 삽입되어 실행되고, 또 끝나지 않으면 우선순위가 계속 내려간다.
  - 자연적으로 CPU 를 비교적 오래 사용하는 CPU bound process 는 우선순위가 낮아지고, CPU를 비교적 적게 사용하는 I/O bound process 는 우선순위가 높은 큐에서 실행이 끝난다.
- **FIFO 스케쥴러는 정말 쓸모가 없는 친구일까요? 어떤 시나리오에 사용하면 좋을까요?**
  - **사용 시나리오**
    1. 단순성 및 예측 가능성이 중요한 경우
    - **단순한 시스템:** FIFO는 구현이 매우 간단하므로, 복잡도를 최소화하려는 작은 규모 또는 임베디드 시스템에서 유용합니다.
    - **작업 순서 보장:** 특정 작업들이 도착한 순서대로 처리되어야 하는 시나리오에서 FIFO는 이러한 순서를 보장합니다.
    1. 짧은 작업이 많은 경우
    - **작업 시간의 예측:** 모든 작업의 실행 시간이 짧고 비슷하다면, FIFO는 간단하고 효율적인 방법이 될 수 있습니다.
    1. 부하가 낮은 시스템
    - **낮은 CPU 사용률:** 시스템에 동시에 실행되는 프로세스의 수가 적고 CPU 사용률이 낮을 때, FIFO는 간단하고 효율적으로 작업을 처리할 수 있습니다.
- **우리는 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부릅니다. 스레드는 다른 방식으로 스케줄링을 하나요?**
  - 스케줄링 알고리즘을 "프로세스" 스케줄링 알고리즘이라고 부르는 것은 전통적으로 프로세스가 운영 체제에서 실행 단위로 사용되었기 때문입니다. 그러나 현대의 운영 체제에서는 "스레드"가 실제 스케줄링의 기본 단위로 더 자주 사용됩니다. 스레드는 프로세스 내에서 동작하는 더 작은 실행 단위이며, 각각 독립적인 실행 흐름을 가집니다.
- **유저 스레드와 커널 스레드의 스케쥴링 알고리즘은 똑같을까요?**


### **8. 뮤텍스와 세마포어의 차이점은 무엇인가요**

- **뮤텍스 vs. 세마포어**
  
- **이진 세마포어와 뮤텍스의 차이에 대해 설명해 주세요.**

  <details>
  <summary>Binary Semaphore vs. Mutex</summary>

  ![Untitled](https://github.com/ddoddii/Computer-Science-Study/assets/95014836/1341d35c-0559-49fe-9020-85fe7d7fe65f)

  </details>

- **Lock을 얻기 위해 대기하는 프로세스들은 Spin Lock 기법을 사용할 수 있습니다. 이 방법의 장단점은 무엇인가요? 단점을 해결할 방법은 없을까요?**

 

- **뮤텍스와 세마포어 모두 커널이 관리하기 때문에, Lock을 얻고 방출하는 과정에서 시스템 콜을 호출해야 합니다. 이 방법의 장단점이 있을까요? 단점을 해결할 수 있는 방법은 없을까요?**

```text
시스템 콜의 단점 - 커널이랑 스위칭하면서 오버헤드가 발생하는 것.
실제로 시스템 콜을 안쓰게끔 하는 futex 도 만들었다.
atomic 연산을 쓰면 될 것 같다. 단점은 복잡한 자료구조이면 쓰기 어렵다.  
```



### **9. Deadlock 에 대해 설명해 주세요.**

- **Deadlock 이 동작하기 위한 4가지 조건에 대해 설명해 주세요.**
  - 상호 배제(mutual exclusion) : 한 프로세스가 사용하는 자원을 다른 프로세스가 사용할 수 없을 때
  - 점유와 대기(hold and wait) : 자원을 할당받은 상태에서 다른 자원을 할당받기를 기다리는 상태
  - 비선점(nonpreemptive) : 프로세스가 자원을 얻은 후에는 그 자원을 스스로 해제할 때까지 다른 프로세스에 의해 강제로 빼앗길 수 없습니다.
  - 원형 대기(circular wait) : 두 개 이상의 프로세스가 순환 형태로 자원을 기다리는 상태입니다. 예를 들어, 프로세스 A가 자원 X를 가지고 프로세스 B가 필요로 하는 자원 Y를 기다리고, 프로세스 B는 자원 Y를 가지고 프로세스 A가 필요로 하는 자원 X를 기다리는 상황입니다.
- **그렇다면 3가지만 충족하면 왜 Deadlock 이 발생하지 않을까요?**
  - 이 네 가지 조건 중 하나라도 충족되지 않으면 데드락이 발생하지 않습니다. 예를 들어, 비선점 조건이 충족되지 않으면, 시스템이 필요할 때 어떤 프로세스로부터 자원을 강제로 회수할 수 있으므로 데드락 상태가 해결될 수 있습니다. 또한 순환 대기 조건이 충족되지 않으면, 자원을 기다리는 프로세스 간에 순환적인 대기 사슬이 형성되지 않아 데드락이 발생하지 않습니다. 상호 배제나 보유 대기 조건이 충족되지 않아도 마찬가지입니다.
- **어떤 방식으로 예방할 수 있을까요?**
  1. **상호 배제 조건 극복**: 이 조건을 완전히 제거하는 것은 불가능할 수 있으나, 자원을 공유 가능하게 만들어 상호 배제의 필요성을 최소화할 수 있습니다. 예를 들어, 일부 자원(프린터 등)을 여러 프로세스가 공유할 수 있도록 설계함으로써 상호 배제를 줄일 수 있습니다.
  2. **보유 대기 조건 극복**: 프로세스가 실행되기 전에 필요한 모든 자원을 한 번에 요청하고 할당받도록 하여 이 조건을 방지할 수 있습니다. 즉, 운영체제가 특정 프로세스에 자원을 모두 할당하거나, 아예 할당하지 않는 식으로 배분하는 것이다. 이 방법은 자원 활용도가 낮아지는 단점이 있지만, 데드락을 효과적으로 예방할 수 있습니다.
  3. **비선점 조건 극복**: 이미 할당된 자원을 다른 프로세스가 요구할 경우, 이를 선점할 수 있도록 하는 것입니다. 프로세스가 자원을 기다리는 동안 현재 보유한 자원을 해제하고 필요 시 다시 요청하도록 함으로써 데드락을 예방할 수 있습니다.
  4. **순환 대기 조건 극복**: 모든 자원에 고유한 번호를 할당하고, 프로세스가 번호 순서대로 자원을 요청하도록 함으로써 이 조건을 방지할 수 있습니다. 이 방법은 프로세스가 높은 번호의 자원을 보유하고 있을 때 낮은 번호의 자원을 요청하지 못하도록 하여 순환 대기를 예방합니다.
- **왜 현대 OS는 Deadlock을 처리하지 않을까요?**
  
- **Wait Free와 Lock Free를 비교해 주세요.**

### **10. 프로그램이 컴파일 되어, 실행되는 과정을 간략하게 설명해 주세요.**

프로그램은 디스크에 이진 실행 파일로 존재한다. CPU에서 실행하려면 이 프로그램을 메모리로 가져와서 프로세스 형태로 배치해야 한다.

1. **소스 코드 작성**: 개발자가 특정 프로그래밍 언어로 소스 코드를 작성합니다.
2. **컴파일**: 컴파일러는 소스 코드를 기계어 코드(또는 바이트 코드) (=오브젝트 파일) 로 변환합니다. 이 과정에서 문법 검사, 타입 검사 등이 수행됩니다. 오브젝트 파일은 임의 의 물리 메모리 위치에 적재되도록 설계된 파일이다.
3. **링킹**: 컴파일된 코드(오브젝트 코드)에 필요한 라이브러리나 다른 오브젝트 파일들을 연결하여 실행 가능한 파일을 생성합니다. 이 과정을 **링커**가 담당합니다.
4. **로딩**: 생성된 실행 파일을 메모리에 적재합니다. 이때 **로더**가 실행 파일을 메모리에 적재하고 실행을 준비합니다.
5. **실행**: 프로세스가 메모리에 적재되면 CPU는 명령어를 실행하기 시작합니다.

- **링커와, 로더의 차이에 대해 설명해 주세요.**
  - **링커(Linker)**: 컴파일러가 생성한 하나 이상의 오브젝트 파일들을 결합하고, 필요한 라이브러리 함수들을 추가하여 실행 가능한 파일을 만드는 역할을 합니다.
  - **로더(Loader)**: 디스크에 저장된 실행 파일을 메모리에 적재하여 실행을 위해 준비하는 역할을 합니다. 로더는 실행 파일의 코드와 데이터를 메모리에 적절한 위치에 복사하고, 실행을 시작합니다.
- **컴파일 언어와 인터프리터 언어의 차이에 대해 설명해 주세요.**
  - **컴파일 언어**: 소스 코드 전체를 먼저 기계어로 번역한 후 실행 파일을 생성하여 실행합니다. C, C++ 등이 여기에 속합니다. 컴파일 과정을 거치기 때문에 실행 속도가 빠릅니다.
  - **인터프리터 언어**: 소스 코드를 한 줄씩 읽어서 바로 실행하는 방식입니다. Python, JavaScript 등이 여기에 속합니다. 별도의 컴파일 과정 없이 바로 실행할 수 있지만, 컴파일 언어에 비해 실행 속도가 느릴 수 있습니다.
- **JIT(Just-In-Time) Compiler 에 대해 설명해 주세요.**
  - IT 컴파일러는 프로그램의 실행 시간 중에 필요할 때 실시간으로 바이트 코드를 기계어 코드로 변환하는 기술입니다. 이 방식은 인터프리터 언어의 실행 속도를 향상시키기 위해 사용됩니다. 예를 들어, Java의 JVM(Java Virtual Machine)이나 .NET의 CLR(Common Language Runtime)이 JIT 컴파일을 사용합니다.
- **본인이 사용하는 언어는, 어떤식으로 컴파일 및 실행되는지 설명해 주세요.**
- **Python 같은 언어는 CPython, Jython, PyPy등의 다양한 구현체가 있습니다. 각각은 어떤 차이가 있을까요? 또한, 실행되는 과정 또한 다를까요?**
  - **CPython**: Python의 기본 구현체로, Python 코드를 바이트 코드로 컴파일한 다음 인터프리트하여 실행합니다.
  - **Jython**: Java 플랫폼 위에서 실행되며, Python 코드를 자바 바이트 코드로 변환하여 JVM에서 실행합니다.
  - **PyPy**: JIT 컴파일 기술을 사용하여 Python 코드의 실행 속도를 향상시킨 구현체입니다. 실행 과정 중에 자주 사용되는 코드를 식별하고, 해당 코드를 기계어로 컴파일하여 실행 속도를 빠르게 합니다.
- **우리는 흔히 fork(), exec() 시스템 콜을 사용하여 프로세스를 적재할 수 있다고 배웠습니다. 로더의 역할은 이 시스템 콜과 상관있는 걸까요? 아니면 다른 방식으로 프로세스를 적재할 수 있는 건가요?**
  - **`fork()`**와 **`exec()`** 시스템 콜은 프로세스를 생성하고 새 프로그램을 실행하는 데 사용됩니다. **`fork()`**는 호출한 프로세스의 복사본을 생성하고, **`exec()`**는 새 프로그램을 메모리에 적재하여 실행합니다. 이 과정에서 로더가 **`exec()`**에 의해 실행 파일을 메모리에 적재하는 역할을 합니다. 따라서, 로더는 이 시스템 콜과 직접적인 관련이 있으며, 프로세스를 적재하는 중요한 역할을 담당합니다.

### **11. IPC가 무엇이고, 어떤 종류가 있는지 설명해 주세요.**

협력적인 프로세스들은 데이터를 교환할 수 있는, 즉 서로 데이터를 보내거나 받을 수 있는 프로세스 간 통신(IPC) 기법이 필요하다. 프로세스 간 통신에는 기본적으로 공유 메모리(shared memory)와 메세지 전달(message-passing) 두가지 모델이 있다.
메세지 전달 모델은 적은 양의 데이터를 교환하는데 유용하다.

- **Shared Memory가 무엇이며, 사용할 때 유의해야 할 점에 대해 설명해 주세요.**
  공유 메모리는 두 개 이상의 프로세스가 시스템의 동일한 물리 메모리 영역에 접근할 수 있게 하는 IPC 메커니즘입니다. 이 방법은 데이터를 복사하지 않고 직접 메모리를 공유하기 때문에, 다른 IPC 메커니즘에 비해 통신 속도가 매우 빠릅니다.
  **사용 시 유의해야 할 점**:
  - **동기화**: 여러 프로세스가 동시에 공유 메모리에 접근할 수 있으므로, 데이터 일관성과 무결성을 유지하기 위한 적절한 동기화 기법(예: 뮤텍스, 세마포어)의 사용이 필수적입니다.

- **메시지 큐는 단방향이라고 할 수 있나요?**
  - 메시지 큐는 기본적으로 단방향 통신 채널입니다. 하나의 프로세스가 메시지 큐에 메시지를 보내고(쓰기 작업), 다른 프로세스가 이를 읽는(읽기 작업) 구조입니다. 그러나 실제 사용 시에는 두 프로세스가 각각 메시지 큐를 사용하여 서로에게 메시지를 보낼 수 있기 때문에, 양방향 통신을 구현하는 것도 가능합니다. 이렇게 양방향 통신을 위해 각각의 프로세스가 메시지 큐를 하나씩 사용하면, 두 개의 메시지 큐를 통해 마치 양방향 통신 채널처럼 동작시킬 수 있습니다. 따라서, 메시지 큐 자체는 단방향 통신 메커니즘이지만, 실제 응용 프로그램에서는 양방향 통신으로 활용될 수 있습니다.

### **12. Thread Safe 하다는 것은 어떤 의미인가요**

멀티 쓰레딩 환경에서 여러 스레드가 동시에 같은 코드 블록이나 리소스에 접근하더라도 프로그램의 실행 결과가 올바르게 나오는 것을 의미합니다. 즉, 코드나 리소스가 여러 스레드로부터 동시에 접근되어도 예상치 못한 문제나 데이터의 불일치가 발생하지 않도록 보장하는 것입니다.

- **Thread Safe 를 보장하기 위해 어떤 방법을 사용할 수 있나요?**
  - 공유 데이터에 접근하는 임계 영역에 뮤텍스, 세마포어와 같은 동기화 방법을 이용하여 쓰레드의 데이터 동시 접근을
제한하여 thread safe를 보장할 수 있습니다.
- **Peterson's Algorithm 이 무엇이며, 한계점에 대해 설명해 주세요.**
  
- **Race Condition 이 무엇인가요?**
  - Race Condition은 두 개 이상의 프로세스나 스레드가 공유된 데이터에 동시에 접근하려고 할 때, 그 접근 순서에 따라 실행 결과가 달라질 수 있는 상황을 말합니다. 이러한 상황은 데이터의 일관성과 정확성을 해칠 수 있으며, 예측 불가능한 결과를 초래할 수 있습니다. Race Condition을 방지하기 위해서는 적절한 동기화 메커니즘이 필요합니다.
- **Thread Safe를 구현하기 위해 반드시 락을 사용해야 할까요? 그렇지 않다면, 어떤 다른 방법이 있을까요?**
  - 락을 사용하지 않고 atomic 연산 혹은 atomic 변수를 사용할 수 있습니다. 혹은 공유 자원을 사용하지 않고 메시지 패싱과 같이 데이터를 교환할 수 있습니다. 그러나 복잡한 자료구조에 대해서는 위와 같은 방법이 복잡하고 비효율적일 수 있습니다.

 

### **13. Thread Pool, Monitor, Fork-Join에 대해 설명해 주세요.**


- **Thread Pool을 사용한다고 가정하면, 어떤 기준으로 스레드의 수를 결정할 것인가요?**
  
- **어떤 데이터를 정렬 하려고 합니다. 어떤 방식의 전략을 사용하는 것이 가장 안전하면서도 좋은 성능을 낼 수 있을까요?**


### **14. 캐시 메모리 및 메모리 계층성에 대해 설명해 주세요.**

프로세서가 메모리에 접근하는 속도가 프로세서의 클락 속도보다 훨씬 느리므로 이에 대한 딜레이가 생깁니다.
이러한 딜레이를 해결하기 위해 메모리에 계층을 둔 것이 메모리 계층입니다.
단일 CPU연산으로 접근할 수 있는 레지스터부터, 메인 메모리보다 훨씬 빨리 접근할 수 있는 캐시, 그리고 메인 메모리
로 계층이 구성됩니다.

메인 메모리에서 레지스터로 갈수록 접근 속도는 빨라지나, 저장할 수 있는 크기는 작아집니다.

- **캐시 메모리는 어디에 위치해 있나요?**
  - 캐시 메모리는 CPU 와 주 메모리(RAM) 사이에 위치하는 고속 메모리로, SRAM 기반의 저장 장치이다. (SRAM 은 Static RAM으로, 저장된 데이터가 변하지 않는 RAM이다) 캐시 메모리는 CPU 내부 또는 CPU와 가까운 위치에 배치된다. 이는 CPU가 데이터에 더 빠르게 접근할 수 있도록 하기 위함이다.
  - (RAM = 동네 대형 마트, 캐시 메모리 = 집 앞 편의점)
- **L1, L2 캐시에 대해 설명해 주세요.**
  - L1 캐시는 각 코어에 할당된 캐시이며 캐시 중 가장 빠른 접근속도를 가지고 있습니다.
  - L2 캐시는 L1 캐시보다 느리지만 저장할 수 있는 크기가 더 크며, 일반적으로 여러 코어가 L2캐시를 공유하고 있습니다.
- **캐시 히트, 캐시 미스, 캐시 적중률이란 무엇인가요?**
  - 메모리 접근시 캐시에 타겟 데이터가 물리 메모리까지 가지 않고 캐시에서 데이터를 가져오는 것을 말합니다. 캐시 미스는 반대로 캐시에 타겟 데이터가 없어 직접 물리 메모리에서 데이터를 가져오는 것을 말합니다. 캐시 적중률은 전체 메모리 접근 중, 캐시로부터 데이터를 가져온 비율을 말합니다.
- **캐시에 올라오는 데이터는 어떻게 관리되나요?**
  - 캐시에 적재되는 데이터는 지역성을 기반으로 결정됩니다. 특정 메모리에 접근하면 해당 주소의 근처 데이터(일반적으로 64B)까지 가져와서 캐시에 적재합니다. 또한 캐시가 가득 차게 되면 LRU와 같은 교체 정책을 활용하여 시간적으로 최근에 접근한 데이터를 보존하고 다른 데이터를 적재합니다.

- **캐시간의 동기화는 어떻게 이루어지나요?**

- **캐시 메모리의 Mapping 방식에 대해 설명해 주세요.**
  
- **캐시의 지역성에 대해 설명해 주세요.**
  - 캐시의 효율을 높이기 위해서는 CPU의 데이터 접근 패턴을 통해 CPU가 자주 접근하는 데이터에 대해 어느 정도 예측이 필요합니다. 지역성은 프로그램의 데이터 접근이 모두 균등한 것이 아니라 특정 부분에 더 자주 접근하는 특성을 의미하며, 이러한 지역성은 공간 지역성과 시간 지역성으로 나눌 수 있습니다.
  - **시간 지역성(Temporal Locality):** 한 번 접근한 데이터는 곧 다시 접근될 가능성이 높습니다. (ex. 프로그램에서 구구단 실행)
  - **공간 지역성(Spatial Locality):** 한 데이터 주변의 데이터가 곧 접근될 가능성이 높습니다.

- **캐시의 지역성을 기반으로, 이차원 배열을 가로/세로로 탐색했을 때의 성능 차이에 대해 설명해 주세요.**
  - 일반적으로 이차원 배열을 가로로 접근하는 것이 빠릅니다. 이차원 배열은 가로로 물리 메모리 상에 연속되어 놓여 있으므로 가로로 접근하게 되면 처음 캐시 미스가 발생한 후 근처 64B만큼의 데이터에 대해서는 캐시에서  가져올 수 있습니다.
  - 반면 세로로 접근하게 되면 계속 캐시미스가 발생하며, 다음 열로 넘어갔을 때 비로소 캐시 히트가 발생합니다. 그러나 이차원 배열의 크기가 커서 특정 열을 순회하는 중에 캐시 사이즈가 가득차게 되면 replace가 일어나고 다음 열에서도 캐시 미스가 발생할 수 있습니다.
 - 따라서 가로로 탐색하는 것이 더 빠릅니다. 

- **캐시의 공간 지역성은 어떻게 구현될 수 있을까요? (힌트: 캐시는 어떤 단위로 저장되고 관리될까요?)**

  -  캐시는 특정 데이터에 접근했을 때 해당 데이터만 캐시로 적재하는 것이 아니라, 물리 메모리 상에서 해당 데이터를 포함한 64B 만큼의 데이터를 캐시로 가져옵니다.

### **15.메모리의 연속할당 방식 세 가지를 설명해주세요. (first-fit, best-fit, worst-fit)**



- **worst-fit 은 언제 사용할 수 있을까요?**
 
- **성능이 가장 좋은 알고리즘은 무엇일까요?**

 

### **16. Thrashing 이란 무엇인가요?**



- **Thrashing 발생 시, 어떻게 완화할 수 있을까요?**

  

### **17. 가상 메모리란 무엇인가요?**

가상 메모리는 사용자 프로세스가 자신만의 전용 메모리를 가진다는 환상을 가질 수 있게 해줍니다. 이것은 사용하기 쉬운 시스템을 제공해줍니다. 왜냐하면 프로세스는 연속된 주소 공간을 가지고 있다는 생각을 할 수 있고, 따라서 프로그래머가 데이터를 어디에 저장할지 걱정하지 않아도 됩니다. 가상 메모리는 추가적으로 보호와 고립의 기능도 제공합니다. 



- **가상 메모리가 가능한 이유가 무엇일까요?**

  - 가상 메모리를 사용하더라도 실제 데이터가 올라와 있는 물리 메모리에 접근하는 과정이 필요합니다. 각 프로세스가 다른 가상 메모리의 주소 체계를 가지고 있더라도, MMU를 통해 가상 메모리의 주소를 물리 메모리의 주소로 매핑하는 것이 가능합니다.

  - 두번째로, 실제 데이터가 물리 메모리에 올라와 있지 않더라도 해당 데이터에 접근이 발생하면 그 때 데이터를 물리 메모리에 적재하는 방법으로 가상 메모리를 구현할 수 있습니다.

  - 페이징을 사용하고 있는 현대의 OS에서는 페이지 테이블을 통해 가상 메모리와 물리 메모리를 연결하고, 디맨드 페이징, 즉 스왑 영역에 데이터를 올려놓고 페이지의 필요에 따라 동적으로 물리 메모리에 적재합니다.  


- **페이지 크기에 대한 Trade-Off를 설명해 주세요.**

  - 먼저 단편화에 대한 trade-off가 있습니다. 페이지의 크기가 클수록 페이지의 일부 영역을 사용하지 않아 낭비되는 메모리 즉, 내부 단편화가 심해질 수 있습니다.

  - 두번째로, 페이지 테이블 엔트리와 관련된 trade-off가 있습니다. 페이지의 크기가 클수록 전체 페이지의 개수가 작아져 페이지 테이블 엔트리 수가 줄어듭니다. 이는 페이지 테이블이  메모리에서 차지하는 양을 줄이고, 페이지 테이블을 탐색하는 시간을 줄일 수 있습니다.

  - 세번째로, TLB와 관련된 trade-off가 있습니다. 페이지 크기가 클수록 TLB에 더 많은 페이지를 매핑할 수 있으므로 TLB미스를 줄일 수 있습니다.
 

- **페이지 크기가 커지면, 페이지 폴트가 더 많이 발생한다고 할 수 있나요?**
 
- **세그멘테이션 방식을 사용하고 있다면, 가상 메모리를 사용할 수 없을까요?**

- **가상 메모리를 사용하는 이유가 무엇일까요 ? 스왑 말고 더 중요한 이유는 어떤 것이 있을까요?⭐️**
  - 보안 문제가 있습니다. 각 프로세스가 고유한 주소 공간을 갖게 함으로써 하나의 프로세스가 함부로 다른 프로세스의 물리 메모리에 접근하지 못하게 막는 것이다. 




### **18. 세그멘테이션과 페이징의 차이점은 무엇인가요?**

세그멘테이션은 프로세스의 스택, 데이터, 코드와 같이 논리적 세그먼트로 나누어 물리 메모리에 올리는 방법입니다.
논리적인 세그먼트 단위로 물리 메모리에서 연속되어 있습니다. 물리 메모리는 각 세그먼트의 base와 offset을 
통해 계산됩니다.

페이징은 물리 메모리를 고정된 크기의 프레임으로 나누고 해당 블록에 메모리를 할당하는 것을 의미합니다.

- **페이지와 프레임의 차이에 대해 설명해 주세요.**

  - 페이지는 프로세스의 가상 주소 공간 내에서의 기본 단위이고, 프레임은 물리 메모리의 기본 단위로, 물리 메모리의 사용 가능한 블록을 나타냅니다.
  - 각 페이지는 페이지 테이블을 통해 실제 프레임에 매핑됩니다.

- **내부 단편화와, 외부 단편화에 대해 설명해 주세요.**
  - 내부 단편화는 물리 메모리에서 할당된 연속적인 공간 내에서 사용하지 않는 영역이 발생해 낭비되는 것을 의미하고,
  - 외부 단편화는 물리 메모리에서 할당되지 않은 연속적인 공간의 크기가 충분하지 않아 해당 공간을 활용할 수 없어 
  낭비되는 것을 의미합니다.

- **페이지에서 실제 주소를 어떻게 가져올 수 있는지 설명해 주세요.**
  - 각 프로세스는 각자의 가상 주소 공간이 존재하고, 이러한 각 가상 주소를 실제 물리 메모리의 주소에 대응되는 페이지 테이블을 가지고 있습니다. 가상 주소는 virtual page number와 offset으로 이루어져 있으며, virtual page number를 통해 페이지 테이블 엔트리의 물리 메모리의 프레임 주소를 가져옵니다. 그 후에 offset을 더해 실제 접근하고자 하는 물리 메모리의 주소를 가져올 수 있습니다.
- **어떤 주소공간이 있을 때, 이 공간이 수정 가능한지 확인할 수 있는 방법이 있나요?**
  - 페이지 테이블 엔트리(PTE)에는 페이지에 대응되는 프레임의 주소뿐만 아니라 접근 권한에 대한 정보도 담고 있습니다.
따라서 해당 페이지의 페이지 테이블 엔트리를 통해 확인할 수 있습니다.
- **32비트에서, 페이지의 크기가 1kb 이라면 페이지 테이블의 최대 크기는 몇 개일까요?** 🤯

- **32비트 운영체제는 램을 최대 4G 까지 사용할 수 있습니다. 이 이유를 페이징과 연관 지어서 설명해 주세요.**
  - 32비트 운영체제라는 것은 메모리의 주소를 표기하는데 32개의 비트를 사용한다는 것을 의미 합니다. 
  - 현대의 운영체제는 byte addressable, 즉 바이트 단위로 주소를 할당하므로 2^32바이트 = 4GB만큼의 데이터를 
  표기할 수 있음을 알 수 있습니다. 
- **C/C++ 개발을 하게 되면 Segmentation Fault 라는 에러를 접할 수 있을텐데, 이 에러는 세그멘테이션/페이징과 어떤 관계가 있을까요?**


### **19. TLB는 무엇인가요?**

- **TLB를 쓰면 왜 빨라지나요?**
- **MMU가 무엇인가요?**
- **TLB와 MMU는 어디에 위치해 있나요?**

- **코어가 여러개라면, TLB는 어떻게 동기화 할 수 있을까요?**
- **TLB 관점에서, Context Switching 발생 시 어떤 변화가 발생하는지 설명해 주세요.**

### **20. 동기화를 구현하기 위한 하드웨어적인 해결 방법에 대해 설명해 주세요.**

- **volatile 키워드는 어떤 의미가 있나요?**
- **싱글코어가 아니라 멀티코어라면, 어떻게 동기화가 이뤄질까요?**

### **21. 페이지 교체 알고리즘에 대해 설명해 주세요.**

- **LRU 알고리즘은 어떤 특성을 이용한 알고리즘이라고 할 수 있을까요?**
- **LRU 알고리즘을 구현한다면, 어떻게 구현할 수 있을까요?**
  - 정확한 구현은 어려움. reference bit 으로 timestamp.. 
- **LRU 알고리즘의 단점을 설명해 주세요. 이를 해결할 수 있는 대안에 대해서도 설명해 주세요.**

### **22. File Descriptor와, File System에 에 대해 설명해 주세요.**

- **I-Node가 무엇인가요?**
- **프로그래밍 언어 상에서 제공하는 파일 관련 함수 (Python - open(), Java - BufferedReader/Writer 등)은, 파일을 어떤 방식으로 읽어들이나요?**

### **23. 동기와 비동기, 블로킹과 논블로킹의 차이에 대해 설명해 주세요.**

동기 / 비동기 - 결과가 오냐 안오냐. 
블로킹 / 논블로킹 - 제어권 넘어가냐 안넘어가냐. 

(동기 - 블로킹)  (비동기 - 블로킹)

- 동기 + 논블로킹 :  x
- 비동기 + 블로킹 : 다른 쓰레드한테 요청을 넘겨주면 됨. 대신 쓰레드라는 자원을 추가적으로 사용함.

### **24. 멀티프로세싱과 멀티쓰레딩의 차이는 무엇인가요?⭐️**

멀티프로세싱은 하나의 응용프로그램을 여러 개의 프로세스로 구성하여 프로세스가 하나의 작업을 처리하도록 하는 것입니다. 멀티쓰레딩은 하나의 응용프로그램을 여러 개의 스레드로 구성하고, 각 스레드가 하나의 작업을 처리하도록 하는 것입니다. 

멀티프로세싱의 장점으로는, 프로세스는 독립적인 메모리 영역을 가지므로 하나의 프로세스가 문제가 발생해도 다른 프로세스에 영향을 주지 않는다는 것입니다. 하지만 컨텍스트 스위칭 과정에서 캐시 메모리 초기화 등 많은 오버헤드가 듭니다. 

멀티쓰레딩의 장점은, 프로세스를 생성하는 시스템 콜이 줄어들어 자원을 효율적으로 관리할 수 있습니다. 또한 컨텍스트 스위칭이 빠릅니다. 단점으로는 쓰레드 간에는 코드, 데이터, 힙 영역을 공유하기 때문에 자원 공유의 문제가 생길 수 있다는 점입니다. 


- **그렇다면 멀티쓰레딩의 문제점이라고 했을 때 실제 예시는 무엇인가요?**

- 대표적으로 **race condition** 문제가 있습니다. 여러 개의 쓰레드가 공유 자원에 접근했을 때, 마지막 결과가 실행 순서에 따라 달라지는 것을 race condition 이라고 합니다. 예를 들어, 은행 어플리케이션 상에서 


- **멀티쓰레딩의 문제점을 멀티프로세싱이 해결해줄 수 있나요?**
  - 크롬 & 익스플로러 예시 -> 크롬(멀티프로세스), 익스플로러(멀티쓰레드)
  - 어플리케이션에 따라 다를 것 같음.  공유를 할 필요가 없다 -> 멀티프로세싱


- **python 을 사용한다고 했을 때, 멀티쓰레딩의 문제를 asyncio 가 해결할 수 있나요?**

- **asyncio 를 멀티쓰레딩 대신 사용하라고 하는 이유는 무엇일까요?**


  
### 25. 코루틴과 쓰레드의 차이는 무엇인가요?

쓰레드는 각 태스크에 해당하는 스택 메모리를 할당 받는다. OS는 쓰레드에 대해 스케쥴링을 한다. 동시성 보장 수단이 OS 의 컨텍스트 스위칭이다.

코루틴은 경량화된 쓰레드로, 작업에 쓰레드를 할당하는 것이 아닌 오브젝트를 할당하고, 오브젝트를 스위칭한다. 동시성 보장 수단이 프로그래머 코드 상의 스위칭이다. Object 1 이 Object 2 의 **결과가 나오기까지 기다려야 한다**면, Object 1 은 **Suspend** 되지만, Object 1 을 수행하던 **Thread 는 그대로 유효하기** 때문에 Object 2 도 Object 1 과 **동일한 Thread 에서 실행**될 수 있다.